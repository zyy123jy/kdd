{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyy/.conda/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ..., 3054 3055 3056]\n",
      "50000/50000 [100%] ██████████████████████████████ Elapsed: 505s | Loss: -393132.281\n",
      "0.146479781924\n",
      "0.218751628305\n",
      "0.100650668966\n",
      "50000/50000 [100%] ██████████████████████████████ Elapsed: 509s | Loss: -380363.781\n",
      "47000/50000 [ 94%] ████████████████████████████   ETA: 30s | Loss: -393159.938"
     ]
    }
   ],
   "source": [
    "#### %matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import pandas as pd \n",
    "from pandas import DataFrame, read_csv\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy.matlib\n",
    "from edward.models import (\n",
    "    Categorical, Dirichlet, Empirical, InverseGamma,\n",
    "    MultivariateNormalDiag, Normal, ParamMixture, Mixture, Logistic, Laplace, PointMass, Gamma)\n",
    "\n",
    "X_data = pd.read_csv('./data/data2/X.txt', sep=\"\\t\", header = None)\n",
    "Y1 = pd.read_csv('./data/data2/Y1.txt', sep=\"\\t\", header = None)\n",
    "Y2 = pd.read_csv('./data/data2/Y2.txt', sep=\"\\t\", header = None)\n",
    "Y3 = pd.read_csv('./data/data2/Y3.txt', sep=\"\\t\", header = None)\n",
    "Y4 = pd.read_csv('./data/data2/Y4.txt', sep=\"\\t\", header = None)\n",
    "Y5 = pd.read_csv('./data/data2/Y5.txt', sep=\"\\t\", header = None)\n",
    "T_data = np.array(pd.read_csv('./data/data2/T.txt', sep=\"\\t\", header = None))\n",
    "\n",
    "Y1 = np.array(Y1)/20\n",
    "Y2 = np.array(Y2)/50\n",
    "Y3 = np.array(Y3)\n",
    "Y4 = np.array(Y4)\n",
    "Y5 = np.array(Y5)/10\n",
    "n0 = np.size(T_data,0)\n",
    "m0 = np.size(T_data,1)\n",
    "\n",
    "X_data = np.array(X_data)\n",
    "Mask_T = (T_data>0)*1\n",
    "T_data = np.array((T_data-60)/15)\n",
    "T_data = np.array(Mask_T*(T_data))\n",
    "tmp = np.reshape(np.array(Y3[:,0]),(n0,1))\n",
    "X_data = np.concatenate((X_data,tmp),axis=1)\n",
    "tmp = np.reshape(np.array(Y4[:,0]),(n0,1))\n",
    "X_data = np.concatenate((X_data,tmp),axis=1)\n",
    "D = np.size(X_data,1)\n",
    "E1 = np.zeros([30,5])\n",
    "E2 = np.zeros([30,5])\n",
    "E5 = np.zeros([30,5])\n",
    "\n",
    "for iter in range(0,20):\n",
    "     # validation \n",
    "       \n",
    "    index = np.arange(0,n0)\n",
    "    print(index)\n",
    "    #index = np.delete(index,idx)\n",
    "    index_test = index[(iter)*145:(iter+1)*145]  \n",
    "    index_val = index[(iter+1)*145:(iter+2)*145]  \n",
    "    index_train = index\n",
    "    index_train = np.delete(index_train, index_test)\n",
    "  \n",
    "    X_train = X_data[index_train,:]\n",
    "    Y_train1 = Y1[index_train,0:8]\n",
    "    Y_train2 = Y2[index_train,0:8]\n",
    "    Y_train3 = Y3[index_train,0:8]\n",
    "    Y_train4 = Y4[index_train,0:8]\n",
    "    Y_train5 = Y5[index_train,0:8]\n",
    "    T_train = T_data[index_train,0:8]    \n",
    "\n",
    "    X_val = X_data[index_val,:]\n",
    "    Y_val1 = Y1[index_val,0:8]\n",
    "    Y_val2 = Y2[index_val,0:8]\n",
    "    Y_val3 = Y3[index_val,0:8]\n",
    "    Y_val4 = Y4[index_val,0:8]\n",
    "    Y_val5 = Y5[index_val,0:8]\n",
    "    T_val = T_data[index_val,0:8]    \n",
    "   # index_test = idx\n",
    "    T_test = T_data[index_test,0:8]\n",
    "    Y_test1  = Y1[index_test,0:8]\n",
    "    Y_test2  = Y2[index_test,0:8]\n",
    "    Y_test5  = Y5[index_test,0:8]\n",
    "    X_test = X_data[index_test,:]\n",
    " \n",
    "    N = np.size(T_train,0)\n",
    "    M = np.size(T_train,1)\n",
    "    Ne = np.size(T_test,0)\n",
    "    Mt = np.size(T_test,1)   \n",
    "    D = np.size(X_test,1)\n",
    "    \n",
    "    err10 = 100\n",
    "    err20 = 100\n",
    "    err50 = 100\n",
    "    Md = 5 # modality\n",
    "    Mask_train = np.zeros((Md,N,M))\n",
    "    Mask_train[0,:,:] = (Y_train1>0)*1\n",
    "    Mask_train[1,:,:] = (Y_train2>0)*1\n",
    "    Mask_train[2,:,:] = (Y_train3>0)*1\n",
    "    Mask_train[3,:,:] = (Y_train4>0)*1\n",
    "    Mask_train[4,:,:] = ((Y_train5-Y_train5)==0)*1\n",
    "    Mask_test = np.zeros((Md-2,Ne,Mt))\n",
    "    Mask_test[0,:,:] = (Y_test1>0)*1\n",
    "    Mask_test[1,:,:] = (Y_test2>0)*1\n",
    "    Mask_test[2,:,:] = ((Y_test5-Y_test5)==0)*1      \n",
    "    Mask_val = np.zeros((Md-2,Ne,Mt))\n",
    "    Mask_val[0,:,:] = (Y_val1>0)*1\n",
    "    Mask_val[1,:,:] = (Y_val2>0)*1\n",
    "    Mask_val[2,:,:] = ((Y_val5-Y_val5)==0)*1  \n",
    "    for i_val in range(0,10): \n",
    "        X = tf.placeholder(tf.float32, [N,D])\n",
    "        T = tf.placeholder(tf.float32, [N,M])\n",
    "        Mask = tf.placeholder(tf.float32, [Md,N,M])\n",
    "        Yhat1 = tf.placeholder(tf.float32, [N,M])\n",
    "        Yhat2 = tf.placeholder(tf.float32, [N,M])\n",
    "        Yhat3 = tf.placeholder(tf.float32, [N,M])\n",
    "        Yhat4 = tf.placeholder(tf.float32, [N,M])\n",
    "        Yhat5 = tf.placeholder(tf.float32, [N,M])\n",
    "        sigma_q = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([Md,1]))))\n",
    "        sigma_s = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([Md,1]))))\n",
    "        sigma_y = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([Md,1]))))\n",
    "        sigma_c = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([1]))))\n",
    "        sigma_h = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([1]))))\n",
    "      # parameters ininitialization\n",
    "        h = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([Md]))))\n",
    "        c = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([Md]))))\n",
    "        w = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([D,1]))))\n",
    "        b = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([1]))))\n",
    "        w1 = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([D,1]))))\n",
    "        b1 = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([1]))))\n",
    "        v = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([D,1]))))\n",
    "        a = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([D,1]))))\n",
    "          \n",
    "   # models\n",
    "        sm1 = Normal(loc=(tf.matmul(X,w) + b),scale = sigma_s[0]*tf.ones([N,1],tf.float32))\n",
    "        sm2 = Normal(loc=(tf.matmul(X,w) + b),scale = sigma_s[1]*tf.ones([N,1],tf.float32)) \n",
    "        sm3 = Normal(loc=(tf.matmul(X,w) + b),scale = sigma_s[2]*tf.ones([N,1],tf.float32)) \n",
    "        sm4 = Normal(loc=(tf.matmul(X,w) + b),scale = sigma_s[3]*tf.ones([N,1],tf.float32)) \n",
    "        sm5 = Normal(loc=(tf.matmul(X,w) + b),scale = sigma_s[4]*tf.ones([N,1],tf.float32))\n",
    "        \n",
    "        qm1 = Normal(loc=tf.matmul(X,v) + a[0],scale = sigma_q[0]*tf.ones([N,1],tf.float32)) \n",
    "        qm2 = Normal(loc=tf.matmul(X,v) + a[1],scale = sigma_q[1]*tf.ones([N,1],tf.float32)) \n",
    "        qm3 = Normal(loc=tf.matmul(X,v) + a[2],scale = sigma_q[2]*tf.ones([N,1],tf.float32)) \n",
    "        qm4 = Normal(loc=tf.matmul(X,v) + a[3],scale = sigma_q[3]*tf.ones([N,1],tf.float32)) \n",
    "        qm5 = Normal(loc=tf.matmul(X,v) + a[4],scale = sigma_q[4]*tf.ones([N,1],tf.float32)) \n",
    "        \n",
    "        Z1 = tf.sigmoid(sm1*(T-qm1))*Mask[0,:,:]     \n",
    "        Z2 = tf.sigmoid(sm2*(T-qm2))*Mask[1,:,:]      \n",
    "        Z3 = tf.sigmoid(sm3*(T-qm3))*Mask[2,:,:]     \n",
    "        Z4 = tf.sigmoid(sm4*(T-qm4))*Mask[3,:,:]      \n",
    "        Z5 = tf.sigmoid(sm5*(T-qm5))*Mask[4,:,:]      \n",
    "      \n",
    "        Yhat1 = Normal(loc=(-c[0]*Z1 + h[0])*Mask[0,:,:],scale = sigma_y[0]*tf.ones([N,M],tf.float32))\n",
    "        Yhat2 = Normal(loc=(c[1]*Z2 + h[1])*Mask[1,:,:],scale = sigma_y[1]*tf.ones([N,M],tf.float32))\n",
    "        Yhat3 = Normal(loc=(c[2]*Z3 + h[2])*Mask[2,:,:],scale = sigma_y[2]*tf.ones([N,M],tf.float32))\n",
    "        Yhat4 = Normal(loc=(c[3]*Z4 + h[3])*Mask[3,:,:],scale = sigma_y[3]*tf.ones([N,M],tf.float32))\n",
    "        Yhat5 = Normal(loc=(c[4]*Z5 + h[4])*Mask[4,:,:],scale = sigma_y[4]*tf.ones([N,M],tf.float32))\n",
    "        \n",
    "        qc1 =  Normal(loc=tf.Variable(tf.random_normal([1])),\n",
    "             scale=tf.nn.softplus(tf.Variable(tf.random_normal([1]))))\n",
    "        qh1 =  Normal(loc=tf.Variable(tf.random_normal([1])),\n",
    "             scale=tf.nn.softplus(tf.Variable(tf.random_normal([1]))))        \n",
    "        qq1 = Normal(loc=tf.Variable(tf.random_normal([N,1])),\n",
    "             scale=tf.nn.softplus(tf.Variable(tf.random_normal([N,1]))))\n",
    "        qq2 = Normal(loc=tf.Variable(tf.random_normal([N,1])),\n",
    "             scale=tf.nn.softplus(tf.Variable(tf.random_normal([N,1]))))\n",
    "        qq3 = Normal(loc=tf.Variable(tf.random_normal([N,1])),\n",
    "             scale=tf.nn.softplus(tf.Variable(tf.random_normal([N,1]))))\n",
    "        qq4 = Normal(loc=tf.Variable(tf.random_normal([N,1])),\n",
    "             scale=tf.nn.softplus(tf.Variable(tf.random_normal([N,1]))))\n",
    "        qq5 = Normal(loc=tf.Variable(tf.random_normal([N,1])),\n",
    "             scale=tf.nn.softplus(tf.Variable(tf.random_normal([N,1]))))\n",
    "        latent_vars = {qm1:qq1, qm2:qq2,qm3:qq3,qm4:qq4,qm5:qq5}\n",
    "        data = {X:X_train, T:T_train, Yhat1:Y_train1, Yhat2:Y_train2, Yhat3:Y_train3, \n",
    "                Yhat4:Y_train4,Yhat5:Y_train5, Mask:Mask_train}        \n",
    "        inference = ed.KLqp(latent_vars,data)\n",
    "        inference.run(n_iter=50000)  \n",
    "        X_val =  tf.cast(X_val,tf.float32)\n",
    "        q11 = tf.matmul(X_val,v) + a[0]\n",
    "        q22 = tf.matmul(X_val,v) + a[1]\n",
    "        q55 = tf.matmul(X_val,v) + a[4]\n",
    "        s1 = tf.matmul(X_val,w) + b\n",
    "        s2 = tf.matmul(X_val,w) + b\n",
    "        s5 = tf.matmul(X_val,w) + b\n",
    "        zval1 = Mask_val[0,:,:]*(tf.sigmoid((T_val-q11)*s1))\n",
    "        Yval1 = -c[0]*zval1+h[0]\n",
    "        zval2 = Mask_val[1,:,:]*tf.sigmoid((T_val-q22)*s2) \n",
    "        Yval2 = c[1]*zval2+h[1]\n",
    "        zval5 = Mask_val[2,:,:]*tf.sigmoid((T_val-q55)*s5) \n",
    "        Yval5 = c[4]*zval5+h[4]\n",
    "        n1 = tf.count_nonzero(Mask_val[0,:,:])\n",
    "        n2 = tf.count_nonzero(Mask_val[1,:,:])    \n",
    "        n5 = tf.count_nonzero(Mask_val[2,:,:])  \n",
    "        err1 = (abs(Mask_val[0,:,:]*(Y_val1[:,:]-Yval1[:,:])))\n",
    "        err2 = (abs(Mask_val[1,:,:]*(Y_val2[:,:]-Yval2[:,:])))\n",
    "        err5 = (abs(Mask_val[2,:,:]*(Y_val5[:,:]-Yval5[:,:])))\n",
    "        err1 = tf.reduce_sum(err1)\n",
    "        err2 = tf.reduce_sum(err2)\n",
    "        err5 = tf.reduce_sum(err5)\n",
    "        err1 = err1.eval()/n1.eval()\n",
    "        err2 = err2.eval()/n2.eval()\n",
    "        err5 = err5.eval()/n5.eval()\n",
    "        if (err1+err2+err5)<(err10+err20+err50):\n",
    "              v0 = v\n",
    "              w0 = w\n",
    "              a0 = a\n",
    "              b0 = b\n",
    "              c0 = c\n",
    "              h0 = h\n",
    "              sigma_s0 = sigma_s\n",
    "              sigma_q0 = sigma_q\n",
    "              sigma_y0 = sigma_y\n",
    "              err10 = err1\n",
    "              err20 = err2\n",
    "              err50 = err5\n",
    "              print(err1)\n",
    "              print(err2)\n",
    "              print(err5)\n",
    "# testing using MAP to estimate s and q\n",
    "# construct the testing graph model\n",
    "    for iter_tt in range(1,5):\n",
    "        Me = iter_tt       \n",
    "        print(\"known time points\")\n",
    "        print(Me)\n",
    "        Xt = tf.placeholder(tf.float32, [Ne,D])\n",
    "        Tt = tf.placeholder(tf.float32, [Ne,Me])  \n",
    "        Maskt = tf.placeholder(tf.float32, [Md-2,Ne,Me])\n",
    "        Yt1 = tf.placeholder(tf.float32,[Ne,Me])\n",
    "        Yt2 = tf.placeholder(tf.float32,[Ne,Me])    \n",
    "        Yt5 = tf.placeholder(tf.float32,[Ne,Me])  \n",
    "# models   \n",
    "\n",
    "        s1 =  Normal(loc=(tf.matmul(Xt,w0) + b0), scale = sigma_s0[0]*tf.ones([Ne,1],tf.float32))\n",
    "        s2 =  Normal(loc=(tf.matmul(Xt,w0) + b0), scale = sigma_s0[1]*tf.ones([Ne,1],tf.float32))\n",
    "        s5 =  Normal(loc=(tf.matmul(Xt,w0) + b0), scale = sigma_s0[4]*tf.ones([Ne,1],tf.float32))\n",
    "        q11 = Normal(loc=tf.matmul(Xt,v0) + a0[0], scale=sigma_q0[0]*tf.ones([Ne,1],tf.float32))\n",
    "        q12 = Normal(loc=tf.matmul(Xt,v0) + a0[1], scale=sigma_q0[1]*tf.ones([Ne,1],tf.float32))\n",
    "        q15 = Normal(loc=tf.matmul(Xt,v0) + a0[4], scale=sigma_q0[4]*tf.ones([Ne,1],tf.float32))\n",
    "        \n",
    "        q_s1 =  Normal(loc=tf.Variable(tf.random_normal([Ne,1])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([Ne,1]))))    \n",
    "        q_s2 = Normal(loc=tf.Variable(tf.random_normal([Ne,1])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([Ne,1])))) \n",
    "        q_s5 = Normal(loc=tf.Variable(tf.random_normal([Ne,1])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([Ne,1])))) \n",
    "        q_q11 = Normal(loc=tf.Variable(tf.random_normal([Ne,1])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([Ne,1]))))\n",
    "        q_q22 = Normal(loc=tf.Variable(tf.random_normal([Ne,1])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([Ne,1]))))\n",
    "        q_q55 = Normal(loc=tf.Variable(tf.random_normal([Ne,1])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([Ne,1]))))\n",
    "        \n",
    "        Zp1 = tf.sigmoid(s1*(Tt-q11))*Maskt[0,:,:]    \n",
    "        Zp2 = tf.sigmoid(s2*(Tt-q12))*Maskt[1,:,:]       \n",
    "        Zp5 = tf.sigmoid(s5*(Tt-q15))*Maskt[2,:,:]       \n",
    "        Yt1 = Normal(loc=(-c0[0]*Zp1+h0[0])*Maskt[0,:,:],scale = sigma_y0[0]*tf.ones([Ne,Me],tf.float32))\n",
    "        Yt2 = Normal(loc=(c0[1]*Zp2+h0[1])*Maskt[1,:,:],scale = sigma_y0[1]*tf.ones([Ne,Me],tf.float32))\n",
    "        Yt5 = Normal(loc=(c0[4]*Zp5+h0[4])*Maskt[2,:,:],scale = sigma_y0[4]*tf.ones([Ne,Me],tf.float32))\n",
    "        data = {Xt:X_test, Tt:T_test[:,0:Me], Maskt:Mask_test[:,:,0:Me], Yt1:Y_test1[:,0:Me], Yt2:Y_test2[:,0:Me],\n",
    "               Yt5: Y_test5[:,0:Me]}\n",
    "        inference = ed.KLqp({s1:q_s1, s2:q_s2, s5:q_s5, q11:q_q11, q12:q_q22, q15:q_q55},data) \n",
    "        inference.run(n_iter=50000)  \n",
    "        \n",
    "        zhat1 = Mask_test[0,:,:]*(tf.sigmoid((T_test-q_q11)*q_s1))\n",
    "        Yhat1 = -c0[0]*zhat1+h0[0]\n",
    "        zhat2 = Mask_test[1,:,:]*tf.sigmoid((T_test-q_q22)*q_s2) \n",
    "        Yhat2 = c0[1]*zhat2+h0[1]\n",
    "        zhat5 = Mask_test[2,:,:]*tf.sigmoid((T_test-q_q55)*q_s5) \n",
    "        Yhat5 = c0[4]*zhat5+h0[4]\n",
    "        err1 = (abs(Mask_test[0,:,Me:Mt]*(Y_test1[:,Me:Mt]-Yhat1[:,Me:Mt])))\n",
    "        err2 = (abs(Mask_test[1,:,Me:Mt]*(Y_test2[:,Me:Mt]-Yhat2[:,Me:Mt])))\n",
    "        err11 = tf.reduce_sum(err1)*20\n",
    "        err22 = tf.reduce_sum(err2)*50\n",
    "        err5 = (abs(Mask_test[2,:,Me:Mt]*(Y_test5[ :,Me:Mt]-Yhat5[:,Me:Mt])))\n",
    "        err55 = tf.reduce_sum(err5)*10    \n",
    "        n1 = tf.count_nonzero(Mask_test[0,:,Me:Mt])\n",
    "        n2 = tf.count_nonzero(Mask_test[1,:,Me:Mt])    \n",
    "        n5 = tf.count_nonzero(Mask_test[2,:,Me:Mt])   \n",
    "        E1[iter,iter_tt] = err11.eval()/n1.eval() \n",
    "        E2[iter,iter_tt] = err22.eval()/n2.eval()\n",
    "        E5[iter,iter_tt] = err55.eval()/n5.eval()        \n",
    "        np.savetxt( str(iter) + str(iter_tt)+\"E1.txt\", E1, delimiter=\",\")\n",
    "        np.savetxt( str(iter) + str(iter_tt)+\"E2.txt\", E2, delimiter=\",\")\n",
    "        np.savetxt( str(iter) + str(iter_tt)+\"E5.txt\", E5, delimiter=\",\")\n",
    "   \n",
    "    X_test =  tf.cast(X_test,tf.float32)\n",
    "    q11 = tf.matmul(X_test,v0) + a[0]\n",
    "    q22 = tf.matmul(X_test,v0) + a0[1]\n",
    "    q55 = tf.matmul(X_test,v0) + a0[4]\n",
    "    s1 = tf.matmul(X_test,w0) + b0\n",
    "    s2 = tf.matmul(X_test,w0) + b0\n",
    "    s5 = tf.matmul(X_val,w0) + b0\n",
    "    zt1 = Mask_test[0,:,:]*(tf.sigmoid((T_test-q11)*s1))\n",
    "    Yt1 = -c0[0]*zt1+h0[0]\n",
    "    zt2 = Mask_test[1,:,:]*tf.sigmoid((T_test-q22)*s2) \n",
    "    Yt2 = c0[1]*zt2+h0[1]\n",
    "    zt5 = Mask_test[2,:,:]*tf.sigmoid((T_test-q55)*s5) \n",
    "    Yt5 = c0[4]*zt5+h0[4]\n",
    "    n1 = tf.count_nonzero(Mask_test[0,:,:])\n",
    "    n2 = tf.count_nonzero(Mask_test[1,:,:])    \n",
    "    n5 = tf.count_nonzero(Mask_test[2,:,:])  \n",
    "    err1 = (abs(Mask_test[0,:,:]*(Yt1[:,:]-Y_test1[:,:])))\n",
    "    err2 = (abs(Mask_test[1,:,:]*(Yt2[:,:]-Y_test2[:,:])))\n",
    "    err5 = (abs(Mask_test[2,:,:]*(Yt5[:,:]-Y_test5[:,:])))\n",
    "    err1 = tf.reduce_sum(err1)*20\n",
    "    err2 = tf.reduce_sum(err2)*50\n",
    "    err5 = tf.reduce_sum(err5)*10\n",
    "    err11 = err1.eval()/n1.eval()\n",
    "    err22 = err2.eval()/n2.eval()\n",
    "    err55 = err5.eval()/n5.eval()\n",
    "    E1[iter,0] = err11\n",
    "    E2[iter,0] = err22\n",
    "    E5[iter,0] = err55\n",
    "    print(\"Mean absolute error on test data:\")        \n",
    "    print(E1)\n",
    "    print(E2) \n",
    "    print(E5)\n",
    "    np.savetxt( str(iter) + str(0)+\"E1.txt\", E1, delimiter=\",\")\n",
    "    np.savetxt( str(iter) + str(0)+\"E2.txt\", E2, delimiter=\",\")\n",
    "    np.savetxt( str(iter) + str(0)+\"E5.txt\", E5, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
